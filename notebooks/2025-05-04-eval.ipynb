{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038c72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from deepeval import evaluate\n",
    "# from deepeval.test_case import LLMTestCase\n",
    "# from deepeval.metrics import SummarizationMetric\n",
    "# from deepeval.models import GeminiModel\n",
    "\n",
    "# def batch_summarization_score(\n",
    "#     input_output_pairs,\n",
    "#     api_key,\n",
    "#     batch_size=100,\n",
    "#     # sleep_time=60,\n",
    "#     # max_retries=3,\n",
    "#     # retry_delay=10\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Evaluates summarization quality in batches using the Gemini model with deepeval,\n",
    "#     including automatic retries for failed evaluations.\n",
    "\n",
    "#     Args:\n",
    "#         input_output_pairs: List of tuples (input, actual_output)\n",
    "#         api_key: Gemini API key string\n",
    "#         batch_size: Number of evaluations per batch to avoid hitting rate limits\n",
    "#         sleep_time: Sleep time in seconds between batches\n",
    "#         max_retries: Number of retry attempts per batch on failure\n",
    "#         retry_delay: Delay between retries in seconds\n",
    "\n",
    "#     Returns:\n",
    "#         List of dicts containing input, actual_output, score, reason\n",
    "#     \"\"\"\n",
    "#     model = GeminiModel(\n",
    "#         model_name=\"gemini-2.0-flash\",\n",
    "#         api_key=api_key,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "\n",
    "#     metric = SummarizationMetric(\n",
    "#         threshold=0.5,\n",
    "#         model=model,\n",
    "#         # assessment_questions=[\n",
    "#         #     \"Is the coverage score based on a percentage of 'yes' answers?\",\n",
    "#         #     \"Does the score ensure the summary's accuracy with the source?\",\n",
    "#         #     \"Does a higher score mean a more comprehensive summary?\"\n",
    "#         # ]\n",
    "#         n=10\n",
    "#     )\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     for i in range(0, len(input_output_pairs), batch_size):\n",
    "#         batch = input_output_pairs[i:i + batch_size]\n",
    "#         test_cases = [LLMTestCase(input=inp, actual_output=out) for inp, out in batch]\n",
    "\n",
    "#         try:\n",
    "#             batch_result = evaluate(test_cases=test_cases, metrics=[metric])\n",
    "#             for test_case, res in zip(batch, batch_result.test_results):\n",
    "#                 results.append(res)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Batch {i // batch_size + 1} failed with error: {e}\")\n",
    "#             for _ in batch:\n",
    "#                 results.append(None)  # Preserve alignment with input\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffc7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from deepeval import evaluate\n",
    "# from deepeval.test_case import LLMTestCase\n",
    "# from deepeval.metrics import SummarizationMetric\n",
    "# from deepeval.models import GeminiModel\n",
    "\n",
    "# async def async_summarization_score(\n",
    "#     input_output_pairs,\n",
    "#     api_key,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Evaluates summarization quality using async individual test case calls with the Gemini model,\n",
    "#     processing all test cases concurrently with asyncio.gather, returning the metric score or 0 on failure.\n",
    "\n",
    "#     Args:\n",
    "#         input_output_pairs: List of tuples (input, actual_output)\n",
    "#         api_key: Gemini API key string\n",
    "\n",
    "#     Returns:\n",
    "#         List of floats containing the summarization score for each test case, or 0 if evaluation fails\n",
    "#     \"\"\"\n",
    "#     model = GeminiModel(\n",
    "#         model_name=\"gemini-2.0-flash\",\n",
    "#         api_key=api_key,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "\n",
    "#     metric = SummarizationMetric(\n",
    "#         threshold=0.5,\n",
    "#         model=model,\n",
    "#         n=10\n",
    "#     )\n",
    "\n",
    "#     async def evaluate_test_case(test_case):\n",
    "#         try:\n",
    "#             result = await evaluate(test_cases=[test_case], metrics=[metric])\n",
    "#             return result.test_results[0].metrics_data[0].score\n",
    "#         except Exception as e:\n",
    "#             print(f\"Test case failed with error: {e}\")\n",
    "#             return 0\n",
    "\n",
    "#     test_cases = [LLMTestCase(input=inp, actual_output=out) for inp, out in input_output_pairs]\n",
    "\n",
    "#     # Process all test cases concurrently using asyncio.gather\n",
    "#     results = await asyncio.gather(\n",
    "#         *[evaluate_test_case(test_case) for test_case in test_cases],\n",
    "#         return_exceptions=True\n",
    "#     )\n",
    "\n",
    "#     # Handle any exceptions returned by gather\n",
    "#     final_results = [result if isinstance(result, float) else 0 for result in results]\n",
    "\n",
    "#     return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82f6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.models import GeminiModel\n",
    "\n",
    "def summarize_100_pairs(\n",
    "    input_output_pairs,\n",
    "    api_key,\n",
    "    # sleep_time=20,\n",
    "    # max_retries=1,\n",
    "    # retry_delay=60\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates summarization quality for 100 pairs using Gemini model and DeepEval.\n",
    "\n",
    "    Args:\n",
    "        input_output_pairs: List of 100 (input, output) tuples.\n",
    "        api_key: Gemini API key.\n",
    "        sleep_time: Optional pause after evaluation (e.g., for chaining jobs).\n",
    "        max_retries: Retry attempts per pair.\n",
    "        retry_delay: Delay between retries.\n",
    "\n",
    "    Returns:\n",
    "        List of dicts or evaluation results.\n",
    "    \"\"\"\n",
    "    # if len(input_output_pairs) != 100:\n",
    "    #     raise ValueError(\"Expected exactly 100 input-output pairs.\")\n",
    "\n",
    "    model = GeminiModel(\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        api_key=api_key,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    metric = SummarizationMetric(\n",
    "        threshold=0.5,\n",
    "        model=model,\n",
    "        n=10\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, (inp, out) in enumerate(input_output_pairs):\n",
    "        try:\n",
    "            test_case = LLMTestCase(input=inp, actual_output=out)\n",
    "            result = evaluate(test_cases=[test_case], metrics=[metric])\n",
    "            results.append(result.test_results[0].metrics_data[0].score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating pair {idx + 1}: {e}\")\n",
    "            results.append(0)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a110d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0513722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/pupipatsingkhorn/Developer/repositories/NanoLLaDA/data/gemini_summaries.csv\").sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff878ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.09s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.6, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.60 because the summary omits answers to several questions that the original text could answer, such as details about Manning's fines, a suicide attempt, hospitalization, and beliefs about the grand jury., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: เมื่อ 12 มี.ค. นายแอนโธนี เทรนกา ผู้พิพากษาศาลกลางในเมืองอเลกซานเดรีย รัฐเวอร์จิเนีย ในสหรัฐฯ สั่งให้เชลซี แมนนิง อดีตนักวิเคราะห์ข่าวกรองของกองทัพสหรัฐฯที่กลายเป็นสตรีข้ามเพศ ผู้ส่งต่อข้อมูลที่เป็นความลับของกองทัพสหรัฐฯไปให้กับเว็บไซต์วิกิลีกส์ ควรได้รับการปล่อยตัวจากเรือนจำ ซึ่งถูกกักขังตั้งแต่เดือน พ.ค.ปีกลายจากกรณีที่ไม่ให้ความร่วมมือกับคณะลูกขุนใหญ่ในการไต่สวนคดีวิกิลีกส์ทันที หลังคณะลูกขุนใหญ่สิ้นสุดการพิจารณานอกจากนี้ นายเทรนกายังปฏิเสธคำร้องของแมนนิงที่ให้ยกเลิกการจ่ายค่าปรับที่ไม่ยอมไปให้การในชั้นศาล ซึ่งเป็นเงินค่าปรับจำนวนทั้งสิ้น 256000 เหรียญสหรัฐฯ หรือราว 8 ล้านบาท ส่วนการพิจารณาฝากขังที่มีกำหนดในวันรุ่งขึ้นก็ให้มีคำสั่งยกเลิก ก่อนหน้านี้ แมนนิงพยายามฆ่าตัวตายแต่ได้รับการช่วยเหลือและถูกนำตัวส่งโรงพยาบาล อาการเริ่มดีขึ้น โดยแมนนิงเชื่อว่าคณะลูกขุนใหญ่ใช้อำนาจในทางมิชอบและเธอยอมอดตายดีกว่าไปให้ปากคำ.\n",
      "  - actual output: ผู้พิพากษาสั่งปล่อยตัว เชลซี แมนนิง อดีตนักวิเคราะห์ข่าวกรอง ผู้เปิดโปงข้อมูลลับให้วิกิลีกส์ หลังถูกคุมขังเพราะไม่ให้ความร่วมมือในการไต่สวนคดีวิกิลีกส์ เนื่องจากคณะลูกขุนใหญ่สิ้นสุดการพิจารณาแล้ว อย่างไรก็ตาม ศาลปฏิเสธคำร้องขอยกเลิกค่าปรับที่ไม่ไปให้การ (256,000 ดอลลาร์) และยกเลิกการพิจารณาฝากขังที่กำลังจะมีขึ้น แมนนิงเคย\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.31s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Summarization (score: 0.4, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.40 because the summary includes extra information not present in the original text. Additionally, the summary fails to answer several questions that the original text addresses, indicating a lack of comprehensive coverage., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ปัตตานี-12 พ.ค.48พ.อ.สมควร แสงภัทรเนตร โฆษกกองอำนวยการเสริมสร้างสันติสุขจังหวัดชายแดนภาคใต้ (กอ.สสส.จชต.) ยืนยันว่า ผู้ปกครองและนักศึกษามหาวิทยาลัยสงขลานครินทร์ วิทยาเขตปัตตานี ไม่ใช่เป้าหมายของการก่อการร้ายในพื้นที่ 3 จังหวัดชายแดนภาคใต้แต่อย่างใด เราติดตามข่าวกรองทางทหาร ซึ่งมีกระบวนการวงรอบข่าวกรองเป็นระบบเดียวที่ใช้อยู่ทั่วโลก เราพบว่า ในห้วงที่ผ่านมานักศึกษาไม่ใช่เป้าหมายของการก่อความไม่สงบ ซึ่งเป็นเรื่องที่น่ายินดีว่า บ้าน เมืองเรานั้นยังไม่ถึงขั้นขนาดนั้น ไม่เคยมีข่าวว่า กลุ่มผู้ก่อความไม่สงบมีเป้าหมายขยายไปถึงกลุ่มนักศึกษา พ.อ.สมควร กล่าว เมื่อเป็นเช่นนี้ จึงขอให้ผู้ปกครองและนักศึกษาไม่ต้องวิตกกังวลในการศึกษาเล่าเรียน เพราะหากมีการทำร้ายนักศึกษาก็จะผลเสียทางการเมืองต่อกลุ่มผู้ก่อความไม่สงบในการแย่งชิงมวลชน แต่สิ่งที่นักศึกษาต้องระวังคือ การที่อาจจะถูกลูกหลง โดยเฉพาะกรณีการลอบวางระเบิดในที่ชุมนุมชน ซึ่งจะต้องระมัดระวังเป็นอย่างมาก แต่เรื่องการที่จะใช้อาวุธทำร้ายนักศึกษานั้น ไม่มีแน่นอน ขอให้นักศึกษาสบายใจได้ \n",
      "  - actual output: กอ.สสส.จชต. ยืนยันว่า นักศึกษาและผู้ปกครอง ม.อ.ปัตตานี ไม่ใช่เป้าหมายก่อการร้ายโดยตรง ไม่มีข่าวกรองว่ากลุ่มก่อความไม่สงบจะทำร้ายนักศึกษาโดยตรง แต่เตือนให้ระวัง \"ลูกหลง\" จากเหตุระเบิดในที่ชุมชน เนื่องจากจะส่งผลเสียต่อการแย่งชิงมวลชนของกลุ่มผู้ก่อความไม่สงบ\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.28s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Summarization (score: 0.2, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.20 because the summary includes extra information not present in the original text, such as defining ตุลาการ as a promoter of justice, protector of rights and freedoms, and guarantor of democracy, stating that ตุลาการ are employees of the people, stating that ตุลาการ must be aware of their duties, serve the people with justice, transparency, and independence, and stating that ตุลาการ should not serve orders or be greedy for bribes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input:  คือตราชู ผู้ชี้ เสรีสิทธิ คือศาลสถิต ยุติธรรม นำสมัย คือหลัก ประกัน ประชาธิปไตย มิใช่อภิชนคนชั้นฟ้า ครุยที่สวม นั้นมา จากภาษี รถที่ขี่ เงินใคร ให้หรูหรา ข้าวที่กิน ดินที่ย่ำ บ้านงามตา ล้วนแต่เงิน ของมหาประชาชนมิได้ อวตาร มาโปรดสัตว์ แต่เป็น ลูกจ้างรัฐ ตั้งแต่ต้น ให้อำนาจ แล้วอย่าหลง ทนงตนว่าเป็นคน เหนือคน ชี้เป็น-ตาย เสาหลัก ต้องเป็นหลัก อันศักดิ์สิทธิ์ ใช่ต้องลม เพียงนิด ก็ล้มหงาย ยิ่งเสาสูง ใจต้องสูง เด่นท้าท้าย ใช่ใจง่าย เห็นเงิน แล้วเออออ ต้องเปิด โลกทัศน์ อย่างชัดเจน ใช่ซ่อนเร้น อ่านตำรา แต่ในหอ ออกบัลลังค์ นั่งเพลิน คำเยินยอ เลือกเหล่ากอ มากอง ห้องทำงาน ตุลาการ คือหนึ่ง อธิปไตย อันเป็นของ คนไทย ไพร่-ชาวบ้าน มิใช่ของ ใครผู้หนึ่ง ซึ่งดักดานแต่เป็น ตุลาการ ประชาชน ฉะนั้นพึง สำนึก มโนทัศน์ ใช่ด้านดัด มืดดับ ด้วยสับสน เปื้อนราคิน กินสินบาท คาดสินบนแล้วแบ่งคน แบ่งชั้น บัญชาชี้ เถิดตุลาการ จงคิด อย่างอิสระ รับภาระ อันหนักหนา ทำหน้าที่ หากรับใช้ ใบสั่ง ดั่งกาลี ตุลาการ เช่นนี้ อย่ามีเลย : อานนท์ นำภา ๖ พฤศจิกายน ๕๓ แก้ไขเพิ่มเติมจากฉบับเดิม ๓ กันยายน ๕๓\n",
      "  - actual output: ตุลาการคือผู้ผดุงความยุติธรรม คุ้มครองสิทธิเสรีภาพ และเป็นหลักประกันประชาธิปไตย มิใช่ชนชั้นปกครองที่มาจากไหน แต่เป็นลูกจ้างของประชาชน ต้องสำนึกในหน้าที่ รับใช้ประชาชนด้วยความยุติธรรม โปร่งใส และเป็นอิสระ อย่ารับใช้ใบสั่งหรือเห็นแก่สินบน เพราะตุลาการคืออธิปไตยของประชาชน ไม่ใช่ของใครคนใดคนหนึ่ง\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:05,  5.72s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.7, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.70 because the summary omits answers to several questions that the original text could answer. However, the summary does not contain any contradictions or extra information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: กอล์ฟยูโรเปี้ยนทัวร์รายการซิซิเลี่ยน โอเพ่น ที่เวอร์ดูร่า กอล์ฟ แอนด์ สปา รีสอร์ท บนเกาะซิซิลี ประเทศอิตาลี วันสุดท้ายปรากฏว่า ธอร์ปยอน โอเลเซ่น โปรเดนมาร์กวัย 22 ปี ทำผลงานตีเพิ่มเข้ามาอีก 3 อันเดอร์ คะแนนรวม 4 วัน 15 อันเดอร์ คว้าแชมป์ไปครอง โดยเฉือนชนะคริส วู้ด โปรอังกฤษที่วันสุดท้ายเร่งเครื่องตีไปถึง 8 อันเดอร์ไปเพียงสโตรกเดียวเท่านั้นส่วนการแข่งขันกอล์ฟเอเชี่ยนทัวร์ รายการพานาโซนิค โอเพ่น ที่กรุงนิว เดลี ประเทศอินเดีย แชมป์ตกเป็นของดิกวีเจย์ ซิงห์ โปรเจ้าถิ่นคะแนนรวม 4 วัน 11 อันเดอร์ เอาชนะซิดดิกูร์ โปรบังกลาเทศที่คว้าอันดับ 2 ไป 2 สโตรก ส่วนแอสกอร์ คูมาร์ ผู้นำวันที่ 3 พลาดตีเกินถึง 3 โอเวอร์ ทำให้จบที่อันดับ 8 ร่วม ขณะที่บุญชู เรืองกิต เป็นโปรไทยที่ทำผลงานดีที่สุดโดยจบที่อันดับ 4 คะแนนรวม 7 อันเดอร์\n",
      "  - actual output: โอเลเซ่น (เดนมาร์ก) คว้าแชมป์ซิซิเลี่ยน โอเพ่น เฉือนวู้ด (อังกฤษ) สโตรกเดียว ด้านซิงห์ (อินเดีย) ชนะพานาโซนิค โอเพ่น ที่อินเดีย บุญชู เรืองกิต โปรไทยจบอันดับ 4\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:05,  5.74s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.9, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.90 because the summary contains no contradictions or extra information. However, the summary omits the answer to the question of whether the rescued girl denied having COVID-19 symptoms., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: 3 สาววัยรุ่นชวนกันมากระโดดแม่น้ำเจ้าพระยา โดยกระโดดลงจากสะพานพระราม 8 ฝั่งธนบุรี ช่วยได้ทัน 1 คน อีกคนนำขึ้นมาได้แต่เสียชีวิตแล้ว ส่วนอีก 1 คน จมหายไป ยังไม่ทราบสาเหตุ เบื้องต้นยืนยันไม่เกี่ยวกับโรคระบาดวันที่ 4 เม.ย. ผู้สื่อข่าวรายงานว่า ทางเจ้าหน้าที่ตำรวจ สน.บวรมงคล รับแจ้งเหตุมีประชาชนกระโดดสะพาน บริเวณกลางสะพานพระราม 8 ฝั่งธนบุรี แขวงบางยี่ขัน เขตบางพลัด กรุงเทพฯจากการตรวจสอบเบื้องต้นพบเป็นเพศหญิง 3 ราย ทางเจ้าหน้าที่ได้ทำการช่วยเหลือขึ้นมาได้แล้ว 1 ราย เสียชีวิต 1 และสูญหายอีก 1 รายทั้งนี้ จากการสอบถาม นางสาว กิ๊บ (นามสมมติ) หนึ่งในสาม ที่กระโดดน้ำ ยืนยันว่าตนเองกับเพื่อนอีก 2 คน ได้ชักชวนกันมากระโดดสะพาน เพราะมีปัญหาทางครอบครัว เบื้องต้นขณะเจ้าหน้าที่มูลนิธิสอบถาม ประมาณ 10 นาที น้องกิ๊บ ไม่มีอาการไอ และแจ้งว่าไม่เคยมีอาการเข้าข่ายในกลุ่มเสี่ยง โควิด-19 แต่อย่างใดด้านแม่ของ น.ส.กิ๊บบอกว่า ลูกสาวเคยไปพบจิตแพทย์ ตอนนี้เรียนหนังสือ และพักอยู่กับเพื่อนๆ โดยเช่าหออยู่ย่านดินแดง ส่วนสาเหตุที่แท้จริงเจ้าหน้าที่กำลังสอบสวน พร้อมระดมออกค้นหาหญิงสาวอีก 1 คน ที่ยังหาไม่เจอ คาดว่าน่าจะจมน้ำเสียชีวิตแล้ว\n",
      "  - actual output: วัยรุ่นหญิง 3 คนกระโดดสะพานพระราม 8, ฝั่งธนบุรี 1 คนรอด, 1 เสียชีวิต และ 1 สูญหาย เหตุจูงใจมาจากปัญหาครอบครัว ไม่เกี่ยวข้องกับโควิด-19 ผู้รอดชีวิตให้ข้อมูล แม่ของเธอเผยว่าเคยพบจิตแพทย์ ขณะที่เจ้าหน้าที่กำลังค้นหาผู้สูญหายที่คาดว่าเสียชีวิตแล้ว\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.36s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.75, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.75 because the summary introduces extra information not present in the original text, such as the grades 7-9 and the specific percentage of students feeling resentful and wanting revenge., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: ประชาไท-20 ม.ค.48 รศ.ดร.สมพร เตรียมชัยศรี คณะสาธารณสุขศาสตร์ มหิดล นำเสนอผลงานวิจัยเรื่องความรุนแรงในเด็ก สายโซ่วงจรของความรุนแรง โดยผลการศึกษาวิจัยชี้ว่า ความรุนแรงที่เกิดขึ้นภายในครอบครัว จะส่งผลถึงความก้าวร้าวของเด็ก เมื่อเด็กถูกถูกกระทำความรุนแรงจากครอบครัวและคนรอบข้าง ก็จะทำให้เกิดความรู้สึกอยากแก้แค้น และเริ่มระบายออกในช่วงระดับมัธยมศึกษา โดยอาจจะสะสมไปจนถึงช่วงอาชีวะศึกษาจนถึงช่วงมีครอบครัว กลายเป็นวัฏจักรความรุนแรงต่อไปเรื่อยๆ ผลการศึกษาวิจัย ระบุ โดยงานวิจัยชิ้นนี้ได้ทำการศึกษาวิจัยเด็กระดับ ป.5-6 จำนวน 370 คน โดยเด็กที่ถูกกระทำรุนแรง 336 คนหรือร้อยละ 90.8 มีพฤติกรรมการแสดงออกหลังถูกกระทำ โดยระเบิดอารมณ์กับพี่น้องร้อยละ 23.5 โกรธอยากแก้แค้นร้อยละ 17.8 แค้นใจถ้ามีโอกาสอยากโต้ตอบร้อยละ 17.3 เมื่อเทียบกับเด็ก ม.1-3 จำนวน 335 คน พบว่าถูกกระทำความรุนแรงด้านร่างกายและจิตใจรวม 252 คน หรือร้อยละ 75.2 โดยส่งผลต่อจิตใจให้เด็กรู้สึกน้อยใจเสียใจร้อยละ 88.8 รู้สึกเศร้าใจร้อยละ 77.2 รู้สึกเจ็บใจแค้นใจอยากโต้ตอบร้อยละ 76.9 อยากแก้แค้นร้อยละ 72.8 รู้สึกอยากระบายอารมณ์กับพี่น้องร้อยละ 62.2 \n",
      "  - actual output: งานวิจัย ม.มหิดล ชี้ ความรุนแรงในครอบครัวส่งผลให้เด็กก้าวร้าวขึ้น เริ่มแสดงออกช่วงมัธยม และสะสมเป็นวัฏจักรความรุนแรงต่อเนื่อง เด็ก ป.5-6 ที่ถูกทำร้าย ร้อยละ 90 มีพฤติกรรมระบายอารมณ์ ขณะที่เด็ก ม.1-3 ร้อยละ 75 รู้สึกเจ็บแค้น อยากแก้แค้น และระบายอารมณ์กับคนใกล้ชิด\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:05,  5.95s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.7, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.70 because the summary fails to address some questions that the original text answers, but it does not contain any contradictions or extra information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: หมายเหตุประเพทไทยสัปดาห์นี้ พบกับ คำ ผกา และ อรรถ บุนนาค มาคุยกันถึงเหตุการณ์เกี่ยวกับ สตรีนิยม ในต่างประเทศที่เพิ่งมีการต่อต้านจากสตรีด้วยกัน ด้วยการรณรงค์ปฏิเสธสตรีนิยม การรณรงค์ดังกล่าวนี้เกิดขึ้นในช่วงราว 2 เดือนเศษที่ผ่านมาบนโลกสังคมออนไลน์ เมื่อมีผู้หญิงจำนวนหนึ่งถ่ายภาพคู่กับกระดาษที่เขียนข้อความขึ้นต้นว่า I dont need feminism และบรรยายเหตุผลต่างๆ ของการปฏิเสธกระแสสตรีนิยม และเผยแพร่ไปบนอินเตอร์เน็ตหมายเหตุประเพทไทยสัปดาห์นี้ จับกระแสความเคลื่อนไหวต่อต้านสตรีนิยมมาวิเคราะห์ และพูดคุยถึงประวัติศาสตร์การต่อสู้ของสตรีนิยมซึ่งนับถอยหลังไปได้ไกลถึงเกือบหนึ่งศตวรรษ โดยเป็นขบวนการต่อสู้ในสังคมตะวันตกเพื่อให้ผู้หญิงมีความเป็นมนุษย์เท่าเทียมกับผู้ชาย จนกระทั่งการต่อสู้เพื่อความเท่าเทียมในเรื่องอื่นๆ รวมถึงการต่อสู้เพื่อจะไม่ถูกเลือกปฏิบัติอันเนื่องจากความเป็นผู้หญิง\n",
      "  - actual output: หมายเหตุประเพทไทยสัปดาห์นี้วิเคราะห์กระแสต่อต้านสตรีนิยมในต่างประเทศ ที่ผู้หญิงบางกลุ่มรณรงค์ \"I dont need feminism\" บนโลกออนไลน์ โดยรายการจะเจาะลึกถึงเหตุผลเบื้องหลังการต่อต้านนี้ พร้อมย้อนรอยประวัติศาสตร์การต่อสู้เพื่อความเท่าเทียมทางเพศในสังคมตะวันตก\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:05,  5.63s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.7, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.70 because the summary omits answers to several questions that the original text could answer. However, the summary does not contain any contradicting or extra information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: วงการเทคโนโลยีของจีนคิดค้นและพัฒนาไม่หยุด ล่าสุดสถาบันต๋าโม๋ (DAMO Academy) สถาบันวิจัยทางวิทยาศาสตร์ของอาลีบาบา ของมหาเศรษฐีจีน แจ็ค หม่า เริ่มทดสอบรถยนต์ไร้คนขับบนท้องถนนแบบจำลองแล้วสำนักข่าวซินหัว เผยแพร่ข่าวนี้ พร้อมคลิปวิดีโอการทดสอบ โดยระบุว่า เป็นการเปิดตัวแพลตฟอร์มทดสอบรถยนต์ไร้คนขับบนท้องถนนแบบจำลองครั้งแรก ที่ใช้เทคโนโลยีเสมือนจริง (Virtual Reality Aystem) ช่วยทดสอบการทำงานของยานพาหนะไร้คนขับในสภาพแวดล้อมจริงแบบเรียลไทม์จากคลิปจะเห็นว่ามีการทดสอบโดยคำนวณถึงรูปแบบที่มีคน หรือยานพาหนะจำลองเข้ามาแทรกในระหว่างขับ เพื่อให้นักวิจัยสร้างและจำลองสถานการณ์ที่ยากลำบากได้ เพื่อช่วยปรับปรุงความแม่นยำในการตรวจจับท้องถนนและยานพาหนะ รวมถึงประสิทธิภาพการทำงานแบบเรียลไทม์ด้วยการจำลองสถานการณ์จริงที่มีความสลับซับซ้อนนี้ใช้เวลา 30 วินาที ทำให้นักวิจัยสามารถจำลองสถานการณ์จำนวนมากได้ นอกจากนั้นตัวเลขไมล์สะสมเสมือนจริงของระบบยังเพิ่มสูงสุดได้ถึง 8 ล้านกิโลเมตรต่อวัน ซึ่งยิ่งเพิ่มประสิทธิภาพและความรวดเร็วในการทดสอบได้ที่มา : สำนักข่าวซินหัว\n",
      "  - actual output: อาลีบาบา (DAMO Academy) เปิดตัวแพลตฟอร์มทดสอบรถยนต์ไร้คนขับบนถนนจำลองแห่งแรกของจีน โดยใช้ VR ช่วยจำลองสภาพแวดล้อมจริงแบบเรียลไทม์ เพื่อทดสอบและปรับปรุงความแม่นยำของระบบรถยนต์ไร้คนขับในสถานการณ์ที่ซับซ้อน ด้วยการจำลองไมล์สะสมสูงสุด 8 ล้านกิโลเมตรต่อวัน ช่วยเพิ่มประสิทธิภาพและความรวดเร็วในการพัฒนา\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:06,  6.15s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Summarization (score: 0.6, threshold: 0.5, strict: False, evaluation model: gemini-2.0-flash, reason: The score is 0.60 because the summary fails to address several questions that the original text answers, indicating a loss of key information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: เมื่อวันที่ 28 มกราคม 2559 ผู้สื่อข่าวรายงานว่า หลังจากที่กระแสตุ๊กตาลูกเทพกำลังมาแรง นอกจากสร้างความเชื่อมั่นกับผู้ที่นิยมแล้ว ยังสร้างความหนักใจให้กับฝ่ายความมั่นคง เพราะล่าสุดถูกนำไปซุกซ่อนยาเสพติดจนกลายเป็นข่าวดังไปถึงประเทศเมียนมา,นายโก่ โก่อู ประธานสื่อมวลชนจังหวัดเมียวดี ประเทศเมียนมา ได้สอบถามมายังผู้สื่อข่าวฝั่งจังหวัดตาก ขอรายละเอียดเกี่ยวกับเรื่องนี้ เนื่องจากสื่อโทรทัศน์ในจังหวัดเมียวดีได้เสนอข่าวนี้ด้วย โดยล่าสุดนายโก่ โก่อู ได้แจ้งมาว่าทางด่านความมั่นคงฝั่งเมียวดี ซึ่งอยู่ที่สะพานมิตรภาพไทย-เมียนมา สั่งเจ้าหน้าที่ด่านตรวจเข้มงวดเรื่องตุ๊กตาทุกชนิด ไม่เว้นแม้แต่ตุ๊กตาลูกเทพด้วย หากมีการจะนำเข้า-ออก ให้มีการนำไปเอกซเรย์ตรวจสิ่งเสพติดทุกตัว,ขณะที่ ด้านด่านชายแดนถาวรฝั่งไทย ก็มีการตรวจเข้มเช่นกัน โดยทหารหน่วยเฉพาะกิจกรมทหารราบที่ 4 ได้ตั้งโต๊ะตรวจสัมภาระแยกจากศุลกากรอีกจุดหนึ่ง แต่เบื้องต้นยังไม่พบมีการนำเข้า-ออกแต่อย่างใด,ส่วนที่สนามบินแม่สอด ผู้สื่อข่าวได้ตระเวนดูเกี่ยวกับการนำตุ๊กตาลูกเทพผ่านเข้า-ออก เบื้องต้นก็ยังไม่พบเช่นกันมีเพียงตุ๊กตากระเป๋าของเด็กเท่านั้น.\n",
      "  - actual output: ตุ๊กตาลูกเทพที่กำลังเป็นที่นิยมถูกนำไปซุกซ่อนยาเสพติด ทำให้ด่านชายแดนไทย-เมียนมาเพิ่มความเข้มงวดในการตรวจตุ๊กตาทุกชนิด โดยเฉพาะที่ด่านเมียวดีสั่งเอกซเรย์ทุกตัว ส่วนด่านไทยก็ตั้งจุดตรวจสัมภาระเพิ่มเติมเพื่อป้องกันการลักลอบขนยาเสพติด\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |          |  0% (0/1) [Time Taken: 00:02, ?test case/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating pair 10: 'NoneType' object has no attribute 'truths'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = summarize_100_pairs(\n",
    "    input_output_pairs=list(\n",
    "        df[[\"body\", \"generated\"]].itertuples(index=False, name=None)\n",
    "    ),\n",
    "    api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88e1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for r in results:\n",
    "#     try:\n",
    "#         scores.append(r.test_results[0].metrics_data[0].score)\n",
    "#     except:\n",
    "#         scores.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbe44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for r in results:\n",
    "#     try:\n",
    "#         if r is None:\n",
    "#             raise ValueError(\"Result is None\")\n",
    "#         scores.append(r.metrics_data[0].score)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         scores.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58eaa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'body': df['body'], 'score': scores})\n",
    "df2.to_csv('score-gemini.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- iPython Config --\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"IPython.extensions.autoreload\" not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
    "else:\n",
    "    get_ipython().run_line_magic(\"reload_ext\", \"autoreload\")\n",
    "%autoreload 2\n",
    "\n",
    "# -- System and Path --\n",
    "import os\n",
    "import sys\n",
    "REPO_PATH = os.path.abspath(os.path.join(\"..\"))\n",
    "if REPO_PATH not in sys.path:\n",
    "    sys.path.append(REPO_PATH)\n",
    "print(f\"REPO_PATH: {REPO_PATH}\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Imports --\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Configuration --\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.REPO_PATH = REPO_PATH\n",
    "        self.SEED = 42\n",
    "config = Config()\n",
    "\n",
    "# -- device\n",
    "def select_device():\n",
    "    device = \"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "device = select_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- datasets\n",
    "data_dir = os.path.join(config.REPO_PATH, \"data\", \"thaisum\", \"raw\")\n",
    "train_data_file = os.path.join(data_dir, \"train.csv\")\n",
    "# valid_data_file = os.path.join(data_dir, \"valid.csv\")\n",
    "# test_data_file = os.path.join(data_dir, \"test.csv\")\n",
    "def load_dataset_from_csv(\n",
    "    train_file: str = None, valid_file: str = None, test_file: str = None\n",
    ") -> DatasetDict:\n",
    "\n",
    "    split_files = {\"train\": train_file,\n",
    "                   \"validation\": valid_file,\n",
    "                   \"test\": test_file}\n",
    "\n",
    "    dct = {}\n",
    "    for split in tqdm(split_files, desc=\"Loading CSV splits\"):\n",
    "        file_path = split_files[split]\n",
    "        if file_path:\n",
    "            # ! [Sample] the first 100 rows for demonstration\n",
    "            df = pd.read_csv(file_path, nrows=100)\n",
    "            dct[split] = Dataset.from_pandas(df)\n",
    "    return DatasetDict(dct)\n",
    "dataset_dict = load_dataset_from_csv(train_file=train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Tokenizer --\n",
    "MODEL_NAME = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# -- Formatting --\n",
    "def format_llada_prompt(example):\n",
    "    instruction = f\"<start_id>user<end_id>\\n{example['body']}<eot_id><start_id>assistant<end_id>\\n{example['summary']}<EOS>\"\n",
    "    tokenized = tokenizer(\n",
    "        instruction, padding=\"max_length\", truncation=True, max_length=1024\n",
    "    )\n",
    "    prompt_end = instruction.find(\"<start_id>assistant<end_id>\")\n",
    "    prompt_tokens = tokenizer(instruction[:prompt_end])[\"input_ids\"]\n",
    "    return {\"input_ids\": tokenized[\"input_ids\"], \"prompt_length\": len(prompt_tokens)}\n",
    "\n",
    "# -- Process and Save --\n",
    "output_dir = os.path.join(config.REPO_PATH, \"data\", \"thaisum\", \"tokenized\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for split in tqdm(dataset_dict, desc=\"Processing splits\"):\n",
    "    print(f\"Processing {split} split...\")\n",
    "    processed_data = dataset_dict[split].map(format_llada_prompt)\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{split}.jsonl\")\n",
    "    processed_data.to_json(output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_id = 126336\n",
    "batch_size = 2\n",
    "lr = 1e-5\n",
    "num_epochs = 1\n",
    "\n",
    "# -- Load tokenized dataset\n",
    "train_file = os.path.join(config.REPO_PATH, \"data\", \"thaisum\", \"tokenized\", \"train.jsonl\")\n",
    "train_dataset = load_dataset(\"json\", data_files={\"train\": train_file})[\"train\"]\n",
    "\n",
    "# -- Load the model\n",
    "print(f\"Loading {MODEL_NAME} model...\")\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "print(f\"{MODEL_NAME} model load successfully.\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# ==== Collate function ====\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([item[\"input_ids\"] for item in batch])\n",
    "    prompt_lengths = torch.tensor([item[\"prompt_length\"] for item in batch])\n",
    "    return {\"input_ids\": input_ids, \"prompt_lengths\": prompt_lengths}\n",
    "\n",
    "# ==== DataLoader ====\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# ==== Optimizer ====\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# ==== Training loop ====\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}\")\n",
    "    for batch in pbar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        prompt_lengths = batch[\"prompt_lengths\"].to(device)\n",
    "\n",
    "        # Mask everything except the prompt\n",
    "        noisy_batch = input_ids.clone()\n",
    "        for i in range(noisy_batch.shape[0]):\n",
    "            noisy_batch[i, prompt_lengths[i]:] = mask_token_id\n",
    "\n",
    "        mask_index = (noisy_batch == mask_token_id)\n",
    "\n",
    "        logits = model(input_ids=noisy_batch).logits\n",
    "        p_mask = torch.ones_like(noisy_batch, dtype=torch.float32).to(device)\n",
    "\n",
    "        token_loss = F.cross_entropy(\n",
    "            logits[mask_index], input_ids[mask_index], reduction=\"none\"\n",
    "        ) / p_mask[mask_index]\n",
    "\n",
    "        loss = token_loss.sum() / input_ids.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nanollada)",
   "language": "python",
   "name": "nanollada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
